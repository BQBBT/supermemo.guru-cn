# 2014: Algorithm SM-17

The newest [SuperMemo](https://supermemo.guru/wiki/SuperMemo) algorithm in its design can be used to summarize its own phylogeny. It can also be used to write the counterfactual history of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition). If there were no dinosaurs, humans might not have emerged or might look differently. However, the entire dino branch of the evolutionary tree could easily be chopped off, and still keep humans safe on their own mammalian branch.

In a similar fashion, we can show a seemingly deterministic chain of linked events in the emergence of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) and [Algorithm SM-17](https://supermemo.guru/wiki/Algorithm_SM-17). This can be used to prove that [Biedalak](https://supermemo.guru/wiki/Biedalak) or [Murakowski](https://supermemo.guru/wiki/Murakowski) were more important for history of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) than [Ebbinghaus](https://supermemo.guru/wiki/Ebbinghaus). Anki was more important than Pimsleur. [Gary Wolf](https://supermemo.guru/wiki/Gary_Wolf) provided more impact than William James.

However, the maximum impact of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) is yet to be seen and confluence of forces may re-arrange those early influences. In particular, with an explosion in legitimate competition, the central role of [SuperMemo](https://supermemo.guru/wiki/SuperMemo) can only be retained with further innovation (e.g. see [neural creativity](https://supermemo.guru/wiki/Neural_creativity)).

Here is how I would explain the entire [Algorithm SM-17](https://supermemo.guru/wiki/Algorithm_SM-17) using the building blocks of history as written for this article:

- the key to long-term retention is to [compute optimum spacing](https://supermemo.guru/wiki/The_birthday_of_spaced_repetition:_July_31,_1985) (1985)
- as spacing depends on [memory complexity](https://supermemo.guru/wiki/Memory_complexity), we need to begin with classifying [items](https://supermemo.guru/wiki/Item) into [difficulty](https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS_(1987)) categories (1987)
- we find the optimum review time by [plotting the forgetting curve](https://supermemo.guru/wiki/Employing_forgetting_curves_in_spaced_repetition_(1991)), which indicates a moment when [retention](https://supermemo.guru/wiki/Retention) drops below an acceptable level (1991)
- to find optimum time in scarce data, we need to use approximations, and it helps to know that [forgetting is exponential](https://supermemo.guru/wiki/Exponential_nature_of_forgetting) (1994)
- as the speed of [forgetting](https://supermemo.guru/wiki/Forgetting) depends on [memory stability](https://supermemo.guru/wiki/Memory_stability), the whole algorithm must be designed with [two component of memory](https://supermemo.guru/wiki/Two_components_of_memory) at its core (1988). The lack of consideration for the model may be the chief mistake made by developers of competitive [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) algorithms, e.g. as in the case of the [neural network approach](https://supermemo.guru/wiki/Neural_networks_in_spaced_repetition) (1997)
- the key power of the two components model is to make it possible to [compute the increase in memory stability at review](https://supermemo.guru/wiki/SuperMemo_Algorithm:_30-year-long_labor) (2005)
- the algorithm must build the model of memory by collecting repetition data. It must be [adaptable to the available information](https://supermemo.guru/wiki/First_adaptable_spaced_repetition_algorithm:_Algorithm_SM-4) (1989)
- before data is available, it is helpful to start with a [universal memory formula](https://supermemo.guru/wiki/Search_for_a_universal_memory_formula) (1990)
- further minor adjustments and improvements can make [a world of difference](https://supermemo.guru/wiki/First_data-driven_spaced_repetition_algorithm:_Algorithm_SM-8) (1995), e.g. post-lapse interval, [absolute difficulty](https://supermemo.guru/wiki/A-Factor), fast multi-dimensional regression, etc.
- [universal metric](https://supermemo.guru/wiki/Universal_metric) is needed to fine-tune optimization parameters in future algorithms (2018)

And so, step by step, [Algorithm SM-17](https://supermemo.guru/wiki/Algorithm_SM-17) has emerged at the top of the evolutionary tree in [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition).